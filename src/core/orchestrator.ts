import { OllamaAdapter } from "../adapters/ollama.js";
import { SSEBus } from "../kernel/bus.js";
import { SkillManager } from "./skills.js";
import { env } from "../config/env.js";
import chalk from "chalk";

/**
 * Sovereign Orchestrator v2.4
 * Agentic Loop: Thought -> Action -> Observation -> Reflection
 */
export class SovereignOrchestrator {
    private ollama = new OllamaAdapter();
    private bus = new SSEBus();
    private skillManager = new SkillManager();

    constructor() {
        this.skillManager.loadAll();
    }

    /**
     * ReAct Execution Loop
     */
    async runSovereignLoop(instruction: string) {
        console.log(chalk.bold.magenta("\nüß† ORCHESTRATOR: Sovereign Agent synchronized."));

        let context = `System: You are an AMF-OS Sovereign Agent. 
Available Skills: \${this.skillManager.getAllSkills().map(s => s.name).join(", ")}
Rules: Use the pattern Thought -> Action -> Observation.`;

        let history = [{ role: "user", content: instruction }];
        let isComplete = false;
        let turn = 0;

        while (!isComplete && turn < 5) {
            turn++;
            console.log(chalk.dim(`\n--- Turn \${turn} ---`));

            // 1. THOUGHT & ACTION
            const thoughtResponse = await this.ollama.chat([
                { role: "system", content: context },
                ...history
            ], { model: "llama4:8b" });

            let fullThought = "";
            for await (const chunk of thoughtResponse) {
                fullThought += chunk;
                process.stdout.write(chalk.gray(chunk));
            }

            // Parse Action from Thought (Simplified for Demo)
            const actionMatch = fullThought.match(/Action: (.*)/);
            if (actionMatch) {
                const action = actionMatch[1];
                console.log(chalk.yellow(`\nüöÄ Action: \${action}`));

                // 2. OBSERVATION
                const observation = await this.executeAction(action);
                console.log(chalk.cyan(`\nüëÅÔ∏è Observation: \${observation}`));
                history.push({ role: "assistant", content: fullThought });
                history.push({ role: "user", content: `Observation: \${observation}` });
            } else {
                isComplete = true;
                // 3. REFLECTION
                await this.reflect(instruction, fullThought);
            }
        }
    }

    private async executeAction(action: string): Promise<string> {
        // Implementation for tool/shell execution
        return "Success: Task completed in sandbox.";
    }

    private async reflect(instruction: string, result: string) {
        console.log(chalk.bold.green("\n‚ú® ORCHESTRATOR: Initiating Reflection hook..."));

        const reflectionPrompt = `Analyze the previous task execution.
Task: \${instruction}
Result: \${result}
Identify: 1. What worked? 2. Any risks? 3. Pattern for Success.`;

        const reflection = await this.ollama.chat([
            { role: "user", content: reflectionPrompt }
        ], { model: "qwen3:coder" });

        let feedback = "";
        for await (const chunk of reflection) {
            feedback += chunk;
        }

        console.log(chalk.dim("üìù Reflection stored in Tactical Memory."));
        // Store in LanceDB (WIP)
    }
}
